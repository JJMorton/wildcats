{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d44e8-1249-4395-a5f4-4c267dab67c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import tensor\n",
    "from sbi import analysis as analysis\n",
    "import scipy.stats\n",
    "import scipy.stats.mstats\n",
    "\n",
    "import inference\n",
    "import inference.priors\n",
    "import inference.plotting\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "# The relevant files. Make sure the data files exist, and that the directories are set up for the output files\n",
    "params_file = \"../data/inference/params_widen2.feather\"\n",
    "stats_file = \"../data/inference/stats_widen2.csv\"\n",
    "samples_file = \"../output/inference/posterior_samples.csv\"\n",
    "posterior_file = \"../output/inference/posterior.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee32b2-9cd4-44e2-8693-796bbad256b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read in data\n",
    "\n",
    "You'll need to have the params.feather file (`params_file` above) and the stats.csv file (`stats_file` above).  \n",
    "Then make sure that the output directories are created (../output/inference and ../plots/inference for the plots).\n",
    "\n",
    "The stats csv has a column named 'index' which tells you which row of the params file the statistics come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35781e99-c995-450a-b707-5197f811843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.read_csv(stats_file, index_col=\"index\").sort_values(\"index\").drop(columns=[\"random_seed\"]).dropna()\n",
    "\n",
    "# Only take the priors that there are summary statistics for in the table above\n",
    "params_df = pd.read_feather(params_file)\n",
    "params_df = params_df[params_df.index.isin(stats_df.index)]\n",
    "\n",
    "# Get the parameters and outputs into torch tensors\n",
    "theta = tensor(params_df.values, dtype=torch.float32)\n",
    "x = tensor(stats_df.values, dtype=torch.float32)\n",
    "\n",
    "# Create joint prior\n",
    "prior = inference.priors.join_priors()\n",
    "if not all(np.array(params_df.columns) == np.array(prior.params)):\n",
    "    raise Exception(\"Parameter names do not match between params file and prior\")\n",
    "# Save prior samples to a feather file:\n",
    "# pd.DataFrame(np.array(prior.sample((100000,))), columns=params_df.columns).to_feather(\"../data/inference/params_new.feather\")\n",
    "\n",
    "num_simulations = len(stats_df.index)\n",
    "num_params = len(params_df.columns)\n",
    "num_stats = len(stats_df.columns)\n",
    "num_samples = num_simulations\n",
    "print(f'Using {num_simulations} simulations, {num_params} params, {num_stats} summary stats and making {num_samples} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623f9ec-607f-4aec-81a8-52a1dcd2d421",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e3e93-c5de-4b81-8b9e-071c7cb5d6c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Create the posterior, this should take\n",
    "- ~3-4 minutes for NPE\n",
    "- ~20 minutes for 10 rounds of SNPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df843563-4337-40a6-9758-cf4151fb681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# posterior = inference.NPE(theta, x, dump_to_file=posterior_file)\n",
    "\n",
    "posterior = inference.SNPE(theta, x, num_rounds=100, density_estimator='maf', dump_to_file=posterior_file, training_args={'use_combined_loss': True})\n",
    "\n",
    "# posterior = inference.NLE(theta, x, dump_to_file=posterior_file, mcmc_parameters={\n",
    "#     \"num_chains\": 1,\n",
    "#     \"thin\": 1,\n",
    "#     \"warmup_steps\": 100,\n",
    "#     \"init_strategy\": \"sir\",\n",
    "#     \"sir_batch_size\": 1000,\n",
    "#     \"sir_num_batches\": 100,\n",
    "# })\n",
    "\n",
    "print(posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085bd249-118a-470a-bf41-2999a836f3d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Alternatively, load the posterior from the pickled file, if training has been done previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5242bc-f9f1-4b37-8ba3-5f78c3393b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'posterior' in globals() and not 'overwrite_posterior' in globals():\n",
    "    print('The posterior is already defined, run this cell again to overwrite it')\n",
    "    overwrite_posterior = True\n",
    "else:\n",
    "    posterior = inference.load_posterior(posterior_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b40b6-25e4-4f16-a841-61af893539bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sampling & Plotting\n",
    "Once you have the posterior, you can run any of these tasks individually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8bfeb-ecda-40fd-80a5-6cc190341672",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Plot the priors, together with samples from `params_file`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a380070-714c-4472-9859-df1ebafd8476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the priors with samples from them, and the samples in the feather file\n",
    "prior_samples = np.array(prior.sample((num_simulations,)))\n",
    "file_samples = np.array(theta)\n",
    "fig, axes = inference.plotting.plot_samples_vs_prior(prior, [prior_samples, file_samples], [\"Prior samples\", \"File samples\"])\n",
    "fig.suptitle(\"Samples drawn from joint prior distribution, compared with parameters from feather file. Red line shows prior distribution.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22361b3-47a4-41f1-b6ab-0829ac95412f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Plot marginal samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b8cbd-fa0f-45fe-9e50-bcc0a1a39134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "posterior_samples = posterior.sample((num_samples,), x=x[0])\n",
    "fig, axes = inference.plotting.plot_samples_vs_prior(prior, posterior_samples, \"Posterior samples\", axsize=4, num_cols=4)\n",
    "for ax, actual in zip(axes, theta[0]):\n",
    "    ax.axvline(actual, ymax=1/1.2, lw=1, c=(0, 0, 0, 0.5), label=\"Actual theta\")\n",
    "    ax.legend()\n",
    "fig.suptitle(f'{posterior_samples.shape[0]} samples drawn from posterior distributions of each parameter')\n",
    "plt.savefig(\"../plots/inference/posterior_samples.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170ca34-09c5-46bf-96fa-4bcd440de150",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Pairplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a9462-c9c7-49fd-91a1-d5b9e82a8de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "posterior_samples = posterior.sample((num_samples,), x=x[0])\n",
    "_ = analysis.pairplot(posterior_samples, labels=prior.params, figsize=(20, 20))\n",
    "plt.savefig(\"../plots/inference/pairplot.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0737361-129a-43ab-b944-b56f6e670298",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Plot means of samples for each parameter, against the actual values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7126932-6e39-4259-a47f-604f5bf7dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_sample_means = np.array([]).reshape((16, 0))\n",
    "theta_sample_errors = np.array([]).reshape((16, 2, 0))\n",
    "num_sample_sets = 100\n",
    "for i in range(num_sample_sets):\n",
    "    print(f'Sampling posterior [{i}/{num_sample_sets}]', end='', flush=True)\n",
    "    samples = np.array(posterior.sample((2000,), x=x[i], show_progress_bars=False)) # (num_params, num_samples)\n",
    "    \n",
    "    means = np.mean(samples, axis=0) # (num_params,)\n",
    "    quantiles = scipy.stats.mstats.mquantiles(samples, prob=[0.025, 0.975], axis=0).T # (num_params, 2)\n",
    "    errors = np.array([np.abs(q - m) for q, m in zip(quantiles, means)]) # (num_params, 2)\n",
    "    \n",
    "    theta_sample_means = np.concatenate((theta_sample_means, means.reshape(num_params, 1)), axis=1)\n",
    "    theta_sample_errors = np.concatenate((theta_sample_errors, errors.reshape(num_params, 2, 1)), axis=2)\n",
    "    print(\"\\r                                  \\r\", end='')\n",
    "    \n",
    "print(f'Sampled posterior {num_sample_sets} times.')\n",
    "# theta_sample_means is of shape (# of params, # of means calculated)\n",
    "# theta_sample_errors is of shape (# of params, 2, # of means calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c5e0b-462c-4456-aa78-97e833a09c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = inference.plotting.create_params_plot(prior, axsize=4, num_cols=4)\n",
    "for ax, actual, mean, err, param in zip(axes, np.array(theta[:num_sample_sets]).T, theta_sample_means, theta_sample_errors, prior.params):\n",
    "    ax.set_xlabel(\"Actual value\")\n",
    "    ax.set_ylabel(\"Mean of posterior samples\")\n",
    "    ax.errorbar(actual, mean, yerr=err, marker='.', color=(0.3, 0.3, 1), linestyle='', elinewidth=1, ecolor=(1, 0.3, 0.3, 0.2))\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    lim = (min(xlim[0], ylim[0]), max(xlim[1], ylim[1]))\n",
    "    ax.plot(lim, lim, ls=\"--\", c=(0, 0, 0, 0.3))\n",
    "plt.savefig(\"../plots/inference/samples_vs_actual.jpg\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wildcats env)",
   "language": "python",
   "name": "wildcats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
