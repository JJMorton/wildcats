{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d44e8-1249-4395-a5f4-4c267dab67c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.distributions\n",
    "from torch import tensor\n",
    "from sbi.inference import SNLE, SNPE, prepare_for_sbi\n",
    "from sbi.utils.user_input_checks import process_prior\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "import scipy.stats\n",
    "import scipy.stats.mstats\n",
    "\n",
    "import inference.priors as priors\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "# The relevant files. Make sure the data files exist, and that the directories are set up for the output files\n",
    "params_file = \"../data/inference/params.feather\"\n",
    "stats_file = \"../data/inference/stats.csv\"\n",
    "samples_file = \"../output/inference/posterior_samples.csv\"\n",
    "posterior_file = \"../output/inference/posterior.pkl\"\n",
    "\n",
    "# Can scale priors to similar sizes. Doesn't seem to help, so leave as False\n",
    "use_normalised_priors = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c9a4a6-4540-41f3-b0fa-0b119d576ea3",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1984c5-f082-4760-a145-c643cb83b865",
   "metadata": {},
   "source": [
    "You'll need to have the params.feather file (`params_file` above) and the stats.csv file (`stats_file` above).  \n",
    "Then make sure that the output directories are created (../output/inference and ../plots/inference for the plots).\n",
    "\n",
    "The stats csv has a column named 'index' which tells you which row of the params file the statistics come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35781e99-c995-450a-b707-5197f811843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.read_csv(stats_file, index_col=\"index\").sort_values(\"index\").drop(columns=[\"random_seed\"]).dropna()\n",
    "\n",
    "# Only take the priors that there are summary statistics for in the table above\n",
    "params_df = pd.read_feather(params_file)\n",
    "params_df = params_df[params_df.index.isin(stats_df.index)]\n",
    "\n",
    "# Scale params table accordingly\n",
    "if use_normalised_priors:\n",
    "    for param in params_df:\n",
    "        params_df[param] -= priors.transforms[param]['loc']\n",
    "        params_df[param] /= priors.transforms[param]['scale']\n",
    "\n",
    "# Get the parameters and outputs into torch tensors\n",
    "theta = tensor(params_df.values, dtype=torch.float32)\n",
    "x = tensor(stats_df.values, dtype=torch.float32)\n",
    "\n",
    "# Create joint prior\n",
    "prior = priors.join_priors(normalise=use_normalised_priors)\n",
    "if not all(np.array(params_df.columns) == np.array(prior.params)):\n",
    "    raise Exception(\"Parameter names do not match between params file and prior\")\n",
    "\n",
    "num_simulations = len(stats_df.index)\n",
    "num_params = len(params_df.columns)\n",
    "num_stats = len(stats_df.columns)\n",
    "num_samples = num_simulations\n",
    "print(f'Using {num_simulations} simulations, {num_params} params ({\"\" if use_normalised_priors else \"un\"}normalised), {num_stats} summary stats and making {num_samples} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1aeb22-e903-4a15-a2cf-1711e1fab2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the priors with samples from them, and the samples in the feather file\n",
    "prior_samples = np.array(prior.sample((num_simulations,)))\n",
    "file_samples = params_df.values\n",
    "fig, axes = priors.plot_samples_vs_prior(prior, [prior_samples, file_samples], [\"Prior samples\", \"File samples\"])\n",
    "fig.suptitle(\"Samples drawn from joint prior distribution, compared with parameters from feather file. Red line shows prior distribution.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623f9ec-607f-4aec-81a8-52a1dcd2d421",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e3e93-c5de-4b81-8b9e-071c7cb5d6c0",
   "metadata": {},
   "source": [
    "Create the posterior, this should take ~3-4 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204d2bde-16d1-4114-ab32-f1be61fcdb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate the posterior\n",
    "inference = SNPE(prior=process_prior(prior)[0], density_estimator='maf')\n",
    "inference = inference.append_simulations(theta, x)\n",
    "density_estimator = inference.train(show_train_summary=True)\n",
    "posterior = inference.build_posterior(density_estimator)\n",
    "with open(posterior_file, \"wb\") as f:\n",
    "    pickle.dump(posterior, f)\n",
    "    print(f'Dumped posterior object to \"{posterior_file}\"')\n",
    "print(posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085bd249-118a-470a-bf41-2999a836f3d4",
   "metadata": {},
   "source": [
    "Alternatively, load the posterior from the pickled file, if training has been done already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5242bc-f9f1-4b37-8ba3-5f78c3393b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the posterior from the pkl file if the training hasn't been run\n",
    "try:\n",
    "    posterior\n",
    "except:\n",
    "    with open(posterior_file, \"rb\") as f:\n",
    "        posterior = pickle.load(f)\n",
    "        print(f'Loaded posterior from \"{posterior_file}\"')\n",
    "        print(posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b40b6-25e4-4f16-a841-61af893539bc",
   "metadata": {},
   "source": [
    "## Sampling & Plotting\n",
    "Once you have the posterior, you can run any of these tasks individually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22361b3-47a4-41f1-b6ab-0829ac95412f",
   "metadata": {},
   "source": [
    "**Take `num_samples` samples from the posterior, save to a csv and plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9a478-90fa-4bb9-9a73-c59881760926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# posterior.set_mcmc_method('slice')\n",
    "# posterior.set_mcmc_parameters({'thin': 1, 'num_chains': 1})\n",
    "posterior_samples = posterior.sample((num_samples,), x=x[0], sample_with_mcmc=False)\n",
    "print(f'Done, saving to \"{samples_file}\"')\n",
    "pd.DataFrame(np.array(posterior_samples), columns=prior.params).to_csv(samples_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af8f088-83c7-4690-8aca-8336894af7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = priors.plot_samples_vs_prior(prior, posterior_samples, \"Posterior samples\", axsize=4, num_cols=4)\n",
    "fig.suptitle(f'{posterior_samples.shape[0]} samples drawn from posterior distributions of each parameter')\n",
    "plt.savefig(\"../plots/inference/posterior_samples.jpg\")\n",
    "plt.show()\n",
    "\n",
    "_ = analysis.pairplot(posterior_samples, labels=prior.params, figsize=(20, 20))\n",
    "plt.show()\n",
    "plt.savefig(\"../plots/inference/pairplot.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0737361-129a-43ab-b944-b56f6e670298",
   "metadata": {},
   "source": [
    "**Plot means of samples for each parameter, against the actual values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7126932-6e39-4259-a47f-604f5bf7dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_sample_means = np.array([]).reshape((16, 0))\n",
    "theta_sample_errors = np.array([]).reshape((16, 2, 0))\n",
    "num_sample_sets = 20\n",
    "for i in range(num_sample_sets):\n",
    "    print(f'Sampling posterior [{i}/{num_sample_sets}]', end='', flush=True)\n",
    "    samples = np.array(posterior.sample((num_samples,), x=x[i], sample_with_mcmc=False, show_progress_bars=False)) # (num_params, num_samples)\n",
    "    \n",
    "    means = np.mean(samples, axis=0) # (num_params,)\n",
    "    quantiles = scipy.stats.mstats.mquantiles(samples, prob=[0.025, 0.975], axis=0).T # (num_params, 2)\n",
    "    errors = np.array([np.abs(q - m) for q, m in zip(quantiles, means)]) # (num_params, 2)\n",
    "    \n",
    "    theta_sample_means = np.concatenate((theta_sample_means, means.reshape(num_params, 1)), axis=1)\n",
    "    theta_sample_errors = np.concatenate((theta_sample_errors, errors.reshape(num_params, 2, 1)), axis=2)\n",
    "    print(\"\\r                                  \\r\", end='')\n",
    "    \n",
    "print(f'Sampled posterior {num_sample_sets} times.')\n",
    "# theta_sample_means is of shape (# of params, # of means calculated)\n",
    "# theta_sample_errors is of shape (# of params, 2, # of means calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c5e0b-462c-4456-aa78-97e833a09c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = priors.create_params_plot(prior, axsize=4, num_cols=4)\n",
    "for ax, actual, mean, err, param in zip(axes, np.array(theta[:num_sample_sets]).T, theta_sample_means, theta_sample_errors, prior.params):\n",
    "    ax.set_xlabel(\"Actual value\")\n",
    "    ax.set_ylabel(\"Mean of posterior samples\")\n",
    "    ax.errorbar(actual, mean, yerr=err, marker='x', linestyle='')\n",
    "    ax.set_xlim(*ax.get_ylim())\n",
    "plt.savefig(\"../plots/inference/samples_vs_actual.jpg\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wildcats env)",
   "language": "python",
   "name": "wildcats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
