{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d44e8-1249-4395-a5f4-4c267dab67c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from os.path import exists\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import tensor\n",
    "from sbi import analysis as analysis\n",
    "import scipy.stats\n",
    "import scipy.stats.mstats\n",
    "\n",
    "import allel\n",
    "from sim.model import GenotypeData\n",
    "from sim.sum_stats import simple_sum\n",
    "\n",
    "import inference\n",
    "import inference.priors\n",
    "import inference.analysis\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "# The relevant files. Make sure the data files exist, and that the directories are set up for the output files\n",
    "FILE_SUFFIX = \"_real\"\n",
    "params_file = \"../data/inference/params_widen2mean.feather\"\n",
    "stats_file = \"../data/inference/stats_widen2mean.csv\"\n",
    "x_observed_file = \"../data/inference/stats_observed.csv\"\n",
    "samples_file = f'../output/inference/posterior_samples{FILE_SUFFIX}.csv'\n",
    "posterior_file = f'../output/inference/posterior{FILE_SUFFIX}.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee32b2-9cd4-44e2-8693-796bbad256b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read in data\n",
    "\n",
    "You'll need to have the params.feather file (`params_file` above) and the stats.csv file (`stats_file` above).  \n",
    "Then make sure that the output directories are created (../output/inference and ../plots/inference for the plots).\n",
    "\n",
    "The stats csv has a column named 'index' which tells you which row of the params file the statistics come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35781e99-c995-450a-b707-5197f811843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.read_csv(stats_file, index_col=\"index\").sort_values(\"index\").drop(columns=[\"random_seed\"]).dropna()\n",
    "\n",
    "# Only take the priors that there are summary statistics for in the table above\n",
    "params_df = pd.read_feather(params_file)\n",
    "params_df = params_df[params_df.index.isin(stats_df.index)]\n",
    "batch_size = int(math.floor(len(params_df.values) / 2))\n",
    "\n",
    "# Get the parameters and outputs into torch tensors\n",
    "theta = tensor(params_df.values[:batch_size], dtype=torch.float32)\n",
    "x = tensor(stats_df.values[:batch_size], dtype=torch.float32)\n",
    "\n",
    "theta_test = tensor(params_df.values[batch_size:batch_size * 2], dtype=torch.float32)\n",
    "x_test = tensor(stats_df.values[batch_size:batch_size * 2], dtype=torch.float32)\n",
    "\n",
    "# Create joint prior\n",
    "prior = inference.priors.join_priors()\n",
    "if not all(np.array(params_df.columns) == np.array(prior.params)):\n",
    "    raise Exception(\"Parameter names do not match between params file and prior\")\n",
    "# Save prior samples to a feather file:\n",
    "# pd.DataFrame(np.array(prior.sample((100000,))), columns=params_df.columns).to_feather(\"../data/inference/params_new.feather\")\n",
    "\n",
    "num_simulations = theta.shape[0]\n",
    "num_tests = theta_test.shape[0]\n",
    "num_params = len(params_df.columns)\n",
    "num_stats = len(stats_df.columns)\n",
    "num_samples = num_tests\n",
    "print(f'Using {num_simulations} simulations, {num_tests} test samples, {num_params} params, {num_stats} summary stats and making {num_samples} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba1730-d7d2-4a54-a1e1-bd6f0ae5c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vcf(vcf_file, info_file):\n",
    "    callset = allel.read_vcf(vcf_file)\n",
    "    pop = np.genfromtxt(info_file, dtype=\"str\", usecols=1, skip_header=1)\n",
    "    subpops = {pop_name: np.where(pop == pop_name)[0] for pop_name in np.unique(pop)}\n",
    "    changekeys = [(\"CAP\", \"captive\"), (\"DOM\", \"domestic\"), (\"WILD\", \"wild\")]\n",
    "    for keys in changekeys:\n",
    "        subpops[keys[1]] = subpops.pop(keys[0])\n",
    "    subpops[\"all_pops\"] = np.arange(len(pop))\n",
    "    data = GenotypeData(callset=callset, subpops=subpops, seq_length=64340295)\n",
    "    return subpops, data\n",
    "\n",
    "try:\n",
    "    x_observed = np.loadtxt(x_observed_file, delimiter=',')\n",
    "    print(f'Loaded summary statistics from \"{x_observed_file}\"')\n",
    "except:\n",
    "    print(\"Reading vcf...\")\n",
    "    geno_pops, geno_data = read_vcf(\"../data/E1/E1.vcf\", \"../data/E1/SampleInfo.txt\")\n",
    "    print(\"Calculating summary statistics...\")\n",
    "    x_observed = np.array(list(simple_sum(geno_data).values()))\n",
    "    np.savetxt(x_observed_file, x_observed, delimiter=',')\n",
    "\n",
    "# Standard deviations away from mean of each statistic\n",
    "mu = x.mean(0)\n",
    "sigma = x.std(0)\n",
    "x_observed_err = (tensor(x_observed) - mu) / sigma\n",
    "print(f'{len(x_observed_err[torch.abs(x_observed_err) < 3])}/{len(x_observed_err)} statistics within 3 standard devs of simulated statistics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623f9ec-607f-4aec-81a8-52a1dcd2d421",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e3e93-c5de-4b81-8b9e-071c7cb5d6c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Create the posterior, this should take\n",
    "- ~3-4 minutes for NPE\n",
    "- ~20 minutes for 10 rounds of SNPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df843563-4337-40a6-9758-cf4151fb681a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if exists(posterior_file) and not 'overwrite_posterior_file' in globals():\n",
    "    print(f'The posterior file already exists ({posterior_file}), run this cell again to overwrite it')\n",
    "    overwrite_posterior_file = True\n",
    "else:\n",
    "    # posterior = inference.NPE(theta, x, dump_to_file=posterior_file)\n",
    "\n",
    "    posterior = inference.SNPE(theta, x, x_o=x_observed, num_rounds=100, density_estimator='maf', dump_to_file=posterior_file, training_args={'use_combined_loss': True})\n",
    "\n",
    "    # posterior = inference.NLE(theta, x, dump_to_file=posterior_file, mcmc_parameters={\n",
    "    #     \"num_chains\": 1,\n",
    "    #     \"thin\": 1,\n",
    "    #     \"warmup_steps\": 100,\n",
    "    #     \"init_strategy\": \"sir\",\n",
    "    #     \"sir_batch_size\": 1000,\n",
    "    #     \"sir_num_batches\": 100,\n",
    "    # })\n",
    "\n",
    "    print(posterior)\n",
    "    posterior_samples = posterior.sample((num_samples,), x=x_test[0])\n",
    "    print(f'Taken {num_samples} samples, saving to \"{samples_file}\"')\n",
    "    pd.DataFrame(np.array(posterior_samples), columns=prior.params).to_csv(samples_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085bd249-118a-470a-bf41-2999a836f3d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Alternatively, load the posterior from the pickled file, if training has been done previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5242bc-f9f1-4b37-8ba3-5f78c3393b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'posterior' in globals() and not 'overwrite_posterior' in globals():\n",
    "    print('The posterior is already defined, run this cell again to overwrite it')\n",
    "    overwrite_posterior = True\n",
    "else:\n",
    "    posterior = inference.load_posterior(posterior_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b40b6-25e4-4f16-a841-61af893539bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sampling & Plotting\n",
    "Once you have the posterior, you can run any of these tasks individually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8bfeb-ecda-40fd-80a5-6cc190341672",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Plot the priors, together with samples from `params_file`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a380070-714c-4472-9859-df1ebafd8476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the priors with samples from them, and the samples in the feather file\n",
    "prior_samples = np.array(prior.sample((num_simulations,)))\n",
    "file_samples = np.array(theta)\n",
    "fig, axes = inference.analysis.plot_samples_vs_prior(prior, [prior_samples, file_samples], [\"Prior samples\", \"File samples\"])\n",
    "fig.suptitle(\"Samples drawn from joint prior distribution, compared with parameters from feather file. Red line shows prior distribution.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0737361-129a-43ab-b944-b56f6e670298",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Plot means of samples for each parameter, against the actual values** (using test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504fe9a-632d-4320-b7e5-2bea6223b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = inference.analysis.plot_means_against_theta(prior, posterior, theta_test[:100], x_test[:100])\n",
    "plt.savefig(f'../plots/inference/samples_vs_actual{FILE_SUFFIX}.jpg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e45eab-c866-499e-8c11-b29d9e3a9e5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Plot marginal samples** (using test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f4483-6a52-4a30-81de-0861263d6944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "posterior_samples = posterior.sample((num_samples,), x=x_test[0])\n",
    "fig, axes = inference.analysis.plot_samples_vs_prior(prior, posterior_samples, \"Posterior samples\", axsize=4, num_cols=4)\n",
    "for ax, actual in zip(axes, theta_test[0]):\n",
    "    ax.axvline(actual, ymax=1/1.2, lw=1, c=(0, 0, 0, 0.5), label=\"Actual theta\")\n",
    "    ax.legend()\n",
    "fig.suptitle(f'{posterior_samples.shape[0]} samples drawn from posterior distributions of each parameter')\n",
    "plt.savefig(f'../plots/inference/posterior_samples{FILE_SUFFIX}.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94495418-f911-4871-8357-94e4b64c0469",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Pairplot** (using test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2888e6-fefb-4fbf-9aa4-de8266bbf986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "posterior_samples = posterior.sample((num_samples,), x=x_test[0])\n",
    "_ = analysis.pairplot(posterior_samples, labels=prior.params, figsize=(20, 20))\n",
    "plt.savefig(f'../plots/inference/pairplot_{FILE_SUFFIX}.jpg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252d903-d8c3-4bfd-9b21-5eeec4aab048",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **KL Divergence** (using real data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046fc1c8-fed8-44a7-9309-167528417b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl = []\n",
    "# num_calcs = 50\n",
    "# for i in range(num_calcs):\n",
    "#     print(f'[{i}/{num_calcs}]', end='', flush=True)\n",
    "#     divergence = inference.analysis.kl_divergence(prior, posterior, x=x_test[i], num_samples=2000, base=2)\n",
    "#     kl.append(divergence)\n",
    "#     print(\"\\r                                  \\r\", end='', flush=False)\n",
    "# print(f'{min(kl)=}, {max(kl)=}, {np.mean(kl)=}, {np.std(kl)=}')\n",
    "\n",
    "divergence = inference.analysis.kl_divergence(prior, posterior, x=x_observed, num_samples=num_samples, base=2)\n",
    "divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fd444b-2bac-4569-8e67-c9b6802b56a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Two NN Intrinsic Dimension Estimation** (using real data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74521d-868a-4d20-875e-ac0858e57ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = posterior.sample((num_samples,), x=x_observed)\n",
    "dimensions = inference.analysis.twonn_dimension(posterior_samples)\n",
    "print(dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22361b3-47a4-41f1-b6ab-0829ac95412f",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **Plot marginal samples** (using real data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b8cbd-fa0f-45fe-9e50-bcc0a1a39134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "posterior_samples = posterior.sample((num_samples,), x=x_observed)\n",
    "fig, axes = inference.analysis.plot_samples_vs_prior(prior, posterior_samples, \"Posterior samples\", axsize=4, num_cols=4)\n",
    "fig.suptitle(f'{posterior_samples.shape[0]} samples drawn from posterior distributions of each parameter')\n",
    "plt.savefig(f'../plots/inference/posterior_samples_real_{FILE_SUFFIX}.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170ca34-09c5-46bf-96fa-4bcd440de150",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **Pairplot** (using real data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a9462-c9c7-49fd-91a1-d5b9e82a8de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "posterior_samples = posterior.sample((num_samples,), x=x_observed)\n",
    "_ = analysis.pairplot(posterior_samples, labels=prior.params, figsize=(20, 20))\n",
    "plt.savefig(f'../plots/inference/pairplot_real_{FILE_SUFFIX}.jpg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wildcats env)",
   "language": "python",
   "name": "wildcats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
